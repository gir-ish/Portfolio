import React from 'react';
import { FaFilePdf } from 'react-icons/fa';

function Publication() {
  return (
    <div style={{ textAlign: "left", maxWidth: "800px", margin: "0 auto", padding: "1rem" }}>
      <h1 style={{ textAlign: "center" }}>Publications</h1>
      
      {/* Conference Papers Section */}
      <h2 style={{ textDecoration: "underline" }}>Accepted</h2>

      <ul>
        {/* Interspeech 2025 papers */}
        <li>
          SOURCE TRACING OF SYNTHETIC SPEECH SYSTEMS THROUGH PARALINGUISTIC PRE-TRAINED REPRESENTATIONS{" "}
          <span style={{ color: "#297aeb" }}>(Eusipco 2025)</span>{" "}
          <a
            href="#"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: <strong>Girish*</strong>, Mohd Mujtaba Akhtar*, Orchid Chetia Phukan*, Drishti Singh, Swarup Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma</em>
          </div>
        </li>
        <br />
{/* ----------------------------------------------------------------------------------------------------------------------------------------------------- */}        
        <li>
          ARE MAMBA-BASED AUDIO FOUNDATION MODELS THE BEST FIT FOR NON-VERBAL EMOTION RECOGNITION?{" "}
          <span style={{ color: "#297aeb" }}>(Eusipco 2025)</span>{" "}
          <a
            href="#"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Mohd Mujtaba Akhtar*, Orchid Chetia Phukan*, <strong>Girish*</strong>, Swarup Ranjan Behera, Sanjib, Arun Balaji Buduru, Rajesh Sharma</em>
          </div>
        </li>
        <br />
{/* ----------------------------------------------------------------------------------------------------------------------------------------------------- */}
        <li>
          Investigating the Reasonable Effectiveness of Speaker Pre-Trained Models and their Synergistic Power for SingMOS Prediction{" "}
          <span style={{ color: "#297aeb" }}>(INTERSPEECH 2025)</span>{" "}
          <a
            href="#"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Orchid Chetia Phukan*, <strong>Girish*</strong>, Mohd Mujtaba Akhtar*, Swarup Ranjan Behera, PhD Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma</em>
          </div>
        </li>
{/* ----------------------------------------------------------------------------------------------------------------------------------------------------- */}

        <br />
        <li>
          Towards Source Attribution of Singing Voice Deepfake with Multimodal Foundation Models{" "}
          <span style={{ color: "#297aeb" }}>(INTERSPEECH 2025)</span>{" "}
          <a
            href="#"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Orchid Chetia Phukan*, <strong>Girish*</strong>, Mohd Mujtaba Akhtar*, Swarup Ranjan Behera, PhD Ranjan Behera, Priyabrata Mallick, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma</em>
          </div>
        </li>
{/* ----------------------------------------------------------------------------------------------------------------------------------------------------- */}

        <br />
        <li>
          PARROT: Synergizing Mamba and Attention-based SSL Pre-Trained Models via Parallel Branch Hadamard Optimal Transport for Speech Emotion Recognition{" "}
          <span style={{ color: "#297aeb" }}>(INTERSPEECH 2025)</span>{" "}
          <a
            href="#"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Orchid Chetia Phukan*, Mohd Mujtaba Akhtar*, <strong>Girish*</strong>, Swarup Ranjan Behera, PhD, Sai Kiran Patibandla, Arun Balaji Buduru, Rajesh Sharma</em>
          </div>
        </li>
{/* ----------------------------------------------------------------------------------------------------------------------------------------------------- */}

        <br />
        <li>
          HYFuse: Aligning Heterogeneous Speech Pre-Trained Representations in Hyperbolic Space for Speech Emotion Recognition{" "}
          <span style={{ color: "#297aeb" }}>(INTERSPEECH 2025)</span>{" "}
          <a
            href="#"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Orchid Chetia Phukan*, <strong>Girish*</strong>, Mohd Mujtaba Akhtar*, Swarup Ranjan Behera, PhD Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma</em>
          </div>
        </li>
{/* ----------------------------------------------------------------------------------------------------------------------------------------------------- */}

        <br />
        <li>
          SNIFR: Boosting Fine-Grained Child Harmful Content Detection Through Audio-Visual Alignment with Cascaded Cross-Transformer{" "}
          <span style={{ color: "#297aeb" }}>(INTERSPEECH 2025)</span>{" "}
          <a
            href="#"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Orchid Chetia Phukan*, Mohd Mujtaba Akhtar*, <strong>Girish*</strong>, Swarup Ranjan Behera, PhD, Abu Osama Siddiqui, Sarthak Jain, Priyabrata Mallick, Sai Kiran Patibandla, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma</em>
          </div>
        </li>
{/* ----------------------------------------------------------------------------------------------------------------------------------------------------- */}

        <br />   
        <li>
          Towards Machine Unlearning for Paralinguistic Speech Processing{" "}
          <span style={{ color: "#297aeb" }}>(INTERSPEECH 2025)</span>{" "}
          <a
            href="#"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Orchid Chetia Phukan*, <strong>Girish*</strong>, Mohd Mujtaba Akhtar*, Shubham Singh, Swarup Ranjan Behera, PhD, Vandana Malayil/Rajan, Ph.D, Muskaan Singh, Arun Balaji Buduru, Rajesh Sharma</em>
          </div>
        </li>
{/* ----------------------------------------------------------------------------------------------------------------------------------------------------- */}

        <br />
        <li>
          Towards Fusion of Neural Audio Codec-based Representations with Spectral for Heart Murmur Classification via Bandit-based Cross-Attention Mechanism{" "}
          <span style={{ color: "#297aeb" }}>(INTERSPEECH 2025)</span>{" "}
          <a
            href="#"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Orchid Chetia Phukan*, <strong>Girish*</strong>, Mohd Mujtaba Akhtar*, Swarup Ranjan Behera, PhD, Priyabrata Mallick, Santanu Roy, Arun Balaji Buduru, Rajesh Sharma</em>
          </div>
        </li>
{/* ----------------------------------------------------------------------------------------------------------------------------------------------------- */}

        <br />

        {/* Existing Accepted items */}
        <li>
          Strong Alone, Stronger Together: Synergizing Modality-Binding Foundation Models with Optimal Transport for Non-Verbal Emotion Recognition{" "}
          <span style={{ color: "#297aeb" }}>(ICASSP 2025)</span>{" "}
          <a
            href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4HIGa7AAAAAJ&citation_for_view=4HIGa7AAAAAJ:9yKSN-GCB0IC"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Orchid Chetia Phukan, Mohd Mujtaba Akhtar*, <strong>Girish*</strong>, Swarup Ranjan Behera, Sishir Kalita, Arun Balaji Buduru, Rajesh Sharma, SR Mahadeva Prasanna</em>
          </div>
        </li>
        <br />
{/* ----------------------------------------------------------------------------------------------------------------------------------------------------- */}        
        <li>
          NeuRO: An Application for Code-Switched Autism Detection in Children{" "}
          <span style={{ color: "#297aeb" }}>(Interspeech Show & Tell 2024)</span>{" "}
          <a
            href="https://ui.adsabs.harvard.edu/abs/2024arXiv240603514M/abstract"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Mohd Mujtaba Akhtar*, <strong>Girish*</strong>, Orchid Chetia Phukan*, Muskaan Singh*</em>
          </div>
        </li>
      </ul>
      

      {/* Preprints/Submissions Section */}
      <h2 style={{ textDecoration: "underline" }}>Preprints / Submitted</h2>
      <ul>
        <li>
          ARE MULTIMODAL FOUNDATION MODELS ALL THAT IS NEEDED FOR EMOFAKE DETECTION?{" "}
          <a
            href="#"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Mohd Mujtaba Akhtar*, <strong>Girish*</strong>, Orchid Chetia Phukan*, Swarup Ranjan Behera, Jaya Sai Kiran Patibandla, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma</em>
          </div>
        </li>
        <br />
        <li>
          SYNERGIZING NEURAL AUDIO CODEC AND SPECTRAL REPRESENTATIONS FOR DEPRESSION DETECTION{" "}
          <a
            href="#"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Mohd Mujtaba Akhtar*, <strong>Girish*</strong>, Orchid Chetia Phukan*, Swarup Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma</em>
          </div>
        </li>
        <br />
        <li>
          Representation Loss Minimization with Randomized Selection Strategy for Efficient Environmental Fake Audio Detection{" "}
          <a
            href="#"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Orchid Chetia Phukan*, <strong>Girish*</strong>, Mohd Mujtaba Akhtar*, Swarup Ranjan Behera*, Nitin Choudhury, Arun Balaji Buduru, Rajesh Sharma, SR Mahadeva Prasanna</em>
          </div>
        </li>
        <br />
        <li>
          Beyond Speech and More: Investigating the Emergent Ability of Speech Foundation Models for Classifying Physiological Time-Series Signals{" "}
          <a
            href="https://arxiv.org/abs/2410.12645"
            target="_blank"
            rel="noopener noreferrer"
            title="View PDF"
          >
            <FaFilePdf style={{ color: 'red', verticalAlign: 'middle' }} />
          </a>
          <div style={{ marginTop: "10px" }}>
            <em>Authors: Orchid Chetia Phukan*, Swarup Ranjan Behera*, <strong>Girish*</strong>, Mohd Mujtaba Akhtar*, Arun Balaji Buduru, Rajesh Sharma</em>
          </div>
        </li>
      </ul>
    </div>
  );
}

export default Publication;
