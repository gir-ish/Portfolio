(this["webpackJsonpmy-portfolio"]=this["webpackJsonpmy-portfolio"]||[]).push([[0],[,,,,,,function(e,t,a){e.exports=a.p+"static/media/1.b06ee6e3.jpg"},,function(e,t,a){e.exports=a.p+"static/media/Girish_Resume.559e3803.pdf"},,,,function(e,t,a){e.exports=a.p+"static/media/audio-vault-enc-dec-application.drawio.f830d3cb.png"},function(e,t,a){e.exports=a(24)},,,,,,,,,function(e,t,a){},function(e,t,a){},function(e,t,a){"use strict";a.r(t);var n=a(1),l=a.n(n),r=a(10),i=a.n(r),o=(a(22),a(5)),c=a(3),m=a(4),s=a(6),u=a.n(s),d=a(11);var h=function(){return l.a.createElement("div",{style:{maxWidth:"900px",margin:"0 auto",textAlign:"center",padding:"1rem"}},l.a.createElement("h1",null,"Girish"),l.a.createElement("div",{style:{display:"flex",alignItems:"center",justifyContent:"center",marginBottom:"2rem",flexWrap:"wrap"}},l.a.createElement("div",{style:{flex:"1 1 300px",textAlign:"left",padding:"1rem"}},l.a.createElement("p",null,"Hello, I\u2019m Girish!"),l.a.createElement("p",null,"I study Computer Science (AI-ML honors) at UPES and will graduate in June 2026."),l.a.createElement("p",null,"I work on research projects like deepfake detection, speech emotion recognition, and audio language models."),l.a.createElement("p",null,"I have worked as a Research Associate at IIIT, Delhi and collaborated with companies like Reliance Jio, ARTVIEWINGS LLC, Suratec Co., LTD, and Ulster University."),l.a.createElement("p",null,"I have published research at conferences like Interspeech and ICASSP, and many are submitted."),l.a.createElement("p",null,"Skilled in Python, Java, C++, TensorFlow, PyTorch.")),l.a.createElement("div",{style:{flex:"1 1 300px",textAlign:"center",padding:"1rem"}},l.a.createElement("img",{src:u.a,alt:"Girish",style:{maxWidth:"50%",height:"auto",borderRadius:"35%"}}))),l.a.createElement("h2",null,"Updates"),l.a.createElement("ul",{style:{textAlign:"left",maxWidth:"600px",margin:"0 auto"}},l.a.createElement("li",null,"Working on new AI projects."),l.a.createElement("li",null,"Published a paper on code-switched autism detection."),l.a.createElement("li",null,"Collaborated on a multimodal personality prediction project."),l.a.createElement("li",null,"Gained more experience with deep learning frameworks.")),l.a.createElement("div",{style:{marginTop:"2rem",textAlign:"center"}},l.a.createElement("h2",null,"Contact"),l.a.createElement("div",{style:{display:"flex",justifyContent:"center",gap:"1.5rem"}},l.a.createElement("a",{href:"https://linkedin.com/in/girish-b794092a1/",target:"_blank",rel:"noopener noreferrer"},l.a.createElement(m.d,{style:{fontSize:"2.5rem",color:"#0e76a8"}})),l.a.createElement("a",{href:"https://github.com/gir-ish",target:"_blank",rel:"noopener noreferrer"},l.a.createElement(m.c,{style:{fontSize:"2.5rem",color:"#333"}})),l.a.createElement("a",{href:"https://scholar.google.com/citations?user=4HIGa7AAAAAJ&hl=en",target:"_blank",rel:"noopener noreferrer"},l.a.createElement(d.a,{style:{fontSize:"2.5rem",color:"#4285F4"}})),l.a.createElement("a",{href:"mailto:girish.research.pr@gmail.com",target:"_blank",rel:"noopener noreferrer"},l.a.createElement(m.a,{style:{fontSize:"2.5rem",color:"red"}})))))},E=a(8),p=a.n(E);var g=function(){return l.a.createElement("div",{style:{padding:"1rem",textAlign:"center"}},l.a.createElement("div",{style:{position:"relative",margin:"0 auto",maxWidth:"900px"}},l.a.createElement("iframe",{src:p.a+"#toolbar=0&navpanes=0&scrollbar=0",width:"100%",height:"800px",style:{border:"none",backgroundColor:"#ffffff"},title:"Girish CV"})),l.a.createElement("div",{style:{marginTop:"1rem"}},l.a.createElement("a",{href:p.a,download:"Girish_Resume.pdf",style:{display:"inline-block",padding:"0.6rem 1.2rem",backgroundColor:"#007bff",color:"#ffffff",textDecoration:"none",borderRadius:"4px",fontSize:"1rem",fontWeight:"bold"}},"Download PDF")))};var f=function(){return l.a.createElement("div",{style:{textAlign:"left",maxWidth:"800px",margin:"0 auto",padding:"1rem"}},l.a.createElement("h1",{style:{textAlign:"center"}},"Publications"),l.a.createElement("h2",{style:{textDecoration:"underline"}},"Conference Papers"),l.a.createElement("ul",null,l.a.createElement("li",null,"Strong Alone, Stronger Together: Synergizing Modality-Binding Foundation Models with Optimal Transport for Non-Verbal Emotion Recognition "," ",l.a.createElement("span",{style:{color:"#297aeb"}},"(ICASSP 2025)")," ",l.a.createElement("a",{href:"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4HIGa7AAAAAJ&citation_for_view=4HIGa7AAAAAJ:9yKSN-GCB0IC",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},l.a.createElement(m.b,{style:{color:"red",verticalAlign:"middle"}})),l.a.createElement("br",null),l.a.createElement("div",{style:{marginTop:"10px"}},l.a.createElement("em",null,"Authors: Orchid Chetia Phukan, Mohd Mujtaba Akhtar*, ",l.a.createElement("strong",null,"Girish*"),", Swarup Ranjan Behera, Sishir Kalita, Arun Balaji Buduru, Rajesh Sharma, SR Mahadeva Prasanna"))),l.a.createElement("br",null),l.a.createElement("li",null,"NeuRO: An Application for Code-Switched Autism Detection in Children"," "," ",l.a.createElement("span",{style:{color:"#297aeb"}},"(Interspeech Show & Tell 2024)")," ",l.a.createElement("a",{href:"https://ui.adsabs.harvard.edu/abs/2024arXiv240603514M/abstract",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},l.a.createElement(m.b,{style:{color:"red",verticalAlign:"middle"}})),l.a.createElement("div",{style:{marginTop:"10px"}},l.a.createElement("em",null,"Authors: Mohd Mujtaba Akhtar*, ",l.a.createElement("strong",null,"Girish*"),", Orchid Chetia Phukan*, Muskaan Singh*")))),l.a.createElement("h2",{style:{textDecoration:"underline"}},"Preprints / Submitted"),l.a.createElement("ul",null,l.a.createElement("li",null,"SOURCE TRACING OF SYNTHETIC SPEECH SYSTEMS THROUGH PARALINGUISTIC PRE-TRAINED REPRESENTATIONS"," ",l.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},l.a.createElement(m.b,{style:{color:"red",verticalAlign:"middle"}})),l.a.createElement("br",null),l.a.createElement("div",{style:{marginTop:"10px"}},l.a.createElement("em",null,"Authors: ",l.a.createElement("strong",null,"Girish*"),", Mohd Mujtaba Akhtar*, Orchid Chetia Phukan*, Drishti Singh, Swarup Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma"))),l.a.createElement("br",null),l.a.createElement("li",null,"ARE MULTIMODAL FOUNDATION MODELS ALL THAT IS NEEDED FOR EMOFAKE DETECTION?"," ",l.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},l.a.createElement(m.b,{style:{color:"red",verticalAlign:"middle"}})),l.a.createElement("br",null),l.a.createElement("div",{style:{marginTop:"10px"}},l.a.createElement("em",null,"Authors: Mohd Mujtaba Akhtar*, ",l.a.createElement("strong",null,"Girish*"),", Orchid Chetia Phukan*, Swarup Ranjan Behera, Jaya Sai Kiran Patibandla, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma"))),l.a.createElement("br",null),l.a.createElement("li",null,"ARE MAMBA-BASED AUDIO FOUNDATION MODELS THE BEST FIT FOR NON-VERBAL EMOTION RECOGNITION?"," ",l.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},l.a.createElement(m.b,{style:{color:"red",verticalAlign:"middle"}})),l.a.createElement("br",null),l.a.createElement("div",{style:{marginTop:"10px"}},l.a.createElement("em",null,"Mohd Mujtaba Akhtar*, Orchid Chetia Phukan*, ",l.a.createElement("strong",null,"Girish*"),", Swarup Ranjan Behera, Sanjib, Arun Balaji Buduru, Rajesh Sharma"))),l.a.createElement("br",null),l.a.createElement("li",null,"SYNERGIZING NEURAL AUDIO CODEC AND SPECTRAL REPRESENTATIONS FOR DEPRESSION DETECTION"," ",l.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},l.a.createElement(m.b,{style:{color:"red",verticalAlign:"middle"}})),l.a.createElement("br",null),l.a.createElement("div",{style:{marginTop:"10px"}},l.a.createElement("em",null,"Authors: Mohd Mujtaba Akhtar*, ",l.a.createElement("strong",null,"Girish*"),", Orchid Chetia Phukan*, Swarup Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma"))),l.a.createElement("br",null),l.a.createElement("li",null,"Representation Loss Minimization with Randomized Selection Strategy for Efficient Environmental Fake Audio Detection"," ",l.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},l.a.createElement(m.b,{style:{color:"red",verticalAlign:"middle"}})),l.a.createElement("br",null),l.a.createElement("div",{style:{marginTop:"10px"}},l.a.createElement("em",null,"Authors: Orchid Chetia Phukan*, ",l.a.createElement("strong",null,"Girish*"),", Mohd Mujtaba Akhtar*, Swarup Ranjan Behera*, Nitin Choudhury, Arun Balaji Buduru, Rajesh Sharma, SR Mahadeva Prasanna"))),l.a.createElement("br",null),l.a.createElement("li",null,"Beyond Speech and More: Investigating the Emergent Ability of Speech Foundation Models for Classifying Physiological Time-Series Signals"," ",l.a.createElement("a",{href:"https://arxiv.org/abs/2410.12645",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},l.a.createElement(m.b,{style:{color:"red",verticalAlign:"middle"}})),l.a.createElement("br",null),l.a.createElement("div",{style:{marginTop:"10px"}},l.a.createElement("em",null,"Authors: Orchid Chetia Phukan*, Swarup Ranjan Behera*, ",l.a.createElement("strong",null,"Girish**"),", Mohd Mujtaba Akhtar**, Arun Balaji Buduru, Rajesh Sharma")))))},y=a(12),b=a.n(y);var A=function(){return l.a.createElement("div",{style:{maxWidth:"1000px",margin:"0 auto",padding:"1rem",textAlign:"left"}},l.a.createElement("h1",null,"Projects"),l.a.createElement("ol",null,l.a.createElement("li",{style:{marginBottom:"2rem"}},l.a.createElement("div",{style:{display:"flex",alignItems:"center",flexWrap:"wrap"}},l.a.createElement("h2",{style:{margin:0}},"Helix: Versatile AI Assistant",l.a.createElement("a",{href:"https://github.com/voice-chat-agent/WhatsApp-bot",target:"_blank",rel:"noopener noreferrer",style:{marginLeft:"1rem"},title:"View on GitHub"},l.a.createElement(m.c,{style:{fontSize:"1.8rem",color:"#333",position:"relative",top:"8px"}}))),l.a.createElement("br",null)),l.a.createElement("br",null),l.a.createElement("ul",null,l.a.createElement("li",null,"AI-Powered Smart Responses: Uses OpenAI GPT, LangChain, and Pinecone for real-time, context-aware interactions, improving customer engagement and automation."),l.a.createElement("li",null,"Versatile \\& Scalable: Easily deploys across industries like healthcare, retail, and finance with minimal code changes, ensuring seamless adaptability."),l.a.createElement("li",null,"Omnichannel \\& Fast: Connects via WhatsApp (Twilio) and phone calls, with a FastAPI backend and async MongoDB for quick, efficient responses."),l.a.createElement("li",null,"Tools Used: LangChain, FastAPI, MongoDB, Twilio."))),l.a.createElement("li",{style:{marginBottom:"2rem"}},l.a.createElement("div",{style:{display:"flex",alignItems:"center",flexWrap:"wrap"}},l.a.createElement("h2",{style:{margin:0}},"TwinVerify: Secure Encryption with Two-Factor Audio and Text Authentication Framework",l.a.createElement("a",{href:"https://github.com/gir-ish/TwinVerify",target:"_blank",rel:"noopener noreferrer",style:{marginLeft:"1rem"},title:"View on GitHub"},l.a.createElement(m.c,{style:{fontSize:"1.8rem",color:"#333",position:"relative",top:"8px"}})))),l.a.createElement("br",null),l.a.createElement("ul",null,l.a.createElement("li",null,"Designed audio encryption and decryption mechanisms with dual-step authentication."),l.a.createElement("li",null,"Combined voice verification with text-based answer matching for secure access."),l.a.createElement("li",null,"Developed the application using Python with the Flask web framework.")),l.a.createElement("img",{src:b.a,alt:"TwinVerify Project",style:{maxWidth:"50%",height:"auto",marginTop:"1rem"}})),l.a.createElement("li",{style:{marginBottom:"2rem"}},l.a.createElement("div",{style:{display:"flex",alignItems:"center",flexWrap:"wrap"}},l.a.createElement("h2",{style:{margin:0}},"Multimodal Personality Prediction Using Contrastive Learning",l.a.createElement("a",{href:"https://github.com/gir-ish/Personality-Detection",target:"_blank",rel:"noopener noreferrer",style:{marginLeft:"1rem"},title:"View on GitHub"},l.a.createElement(m.c,{style:{fontSize:"1.8rem",color:"#333",position:"relative",top:"8px"}})))),l.a.createElement("br",null),l.a.createElement("ul",null,l.a.createElement("li",null,"Built a neural network with two processing paths that uses contrastive learning to predict personality traits (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) from audio and video data."),l.a.createElement("li",null,"Trained the model on both speech and visual cues, improving how it understands and learns personality traits from different sources."),l.a.createElement("li",null,"Optimized the system for better integration of multimodal data, ensuring accurate and reliable personality predictions from real-world audio and video inputs."),l.a.createElement("li",null,"Tools Used: TensorFlow, Hugging Face Transformers."))),l.a.createElement("li",{style:{marginBottom:"2rem"}},l.a.createElement("div",{style:{display:"flex",alignItems:"center",flexWrap:"wrap"}},l.a.createElement("h2",{style:{margin:0}},"Golf Phase Detection and Analysis Application.",l.a.createElement("a",{href:"https://github.com/gir-ish/Golf_Phase_Detection",target:"_blank",rel:"noopener noreferrer",style:{marginLeft:"1rem"},title:"View on GitHub"},l.a.createElement(m.c,{style:{fontSize:"1.8rem",color:"#333",position:"relative",top:"8px"}})))),l.a.createElement("br",null),l.a.createElement("ul",null,l.a.createElement("li",null,"Developed algorithms to detect and classify golf swing phases (setup, backswing, downswing, ball impact, and follow-through) with high accuracy."),l.a.createElement("li",null,"Designed a user-friendly interface for players and coaches, enabling easy review and real-time analysis across different video formats."),l.a.createElement("li",null,"Tools Used: OpenCV, MediaPipe, FFmpeg, Streamlit")))))};a(23);var v=function(){const[e,t]=Object(n.useState)(!1);return l.a.createElement("div",{className:e?"App dark":"App light"},l.a.createElement(o.a,null,l.a.createElement("header",{className:"header"},l.a.createElement("nav",null,l.a.createElement("ul",{className:"nav-links"},l.a.createElement("li",null,l.a.createElement(o.b,{to:"/"},"About")),l.a.createElement("li",null,l.a.createElement(o.b,{to:"/publication"},"Publication")),l.a.createElement("li",null,l.a.createElement(o.b,{to:"/project"},"Project")),l.a.createElement("li",null,l.a.createElement(o.b,{to:"/cv"},"CV"))),l.a.createElement("button",{className:"theme-toggle",onClick:()=>t(!e)},e?l.a.createElement(m.f,{style:{color:"yellow",fontSize:"1.5rem"}}):l.a.createElement(m.e,{style:{color:"blue",fontSize:"1.5rem"}}))),l.a.createElement("hr",{className:"divider"})),l.a.createElement("main",{className:"container"},l.a.createElement(c.c,null,l.a.createElement(c.a,{path:"/",element:l.a.createElement(h,null)}),l.a.createElement(c.a,{path:"/publication",element:l.a.createElement(f,null)}),l.a.createElement(c.a,{path:"/project",element:l.a.createElement(A,null)}),l.a.createElement(c.a,{path:"/cv",element:l.a.createElement(g,null)})))))};var S=e=>{e&&e instanceof Function&&a.e(3).then(a.bind(null,25)).then(t=>{let{getCLS:a,getFID:n,getFCP:l,getLCP:r,getTTFB:i}=t;a(e),n(e),l(e),r(e),i(e)})};i.a.createRoot(document.getElementById("root")).render(l.a.createElement(l.a.StrictMode,null,l.a.createElement(v,null))),S()}],[[13,1,2]]]);
//# sourceMappingURL=main.774e5b65.chunk.js.map