(this["webpackJsonpmy-portfolio"]=this["webpackJsonpmy-portfolio"]||[]).push([[0],[,,,,,,function(e,a,t){e.exports=t.p+"static/media/1.b06ee6e3.jpg"},,function(e,a,t){e.exports=t.p+"static/media/Girish_CV.d1b6d688.pdf"},,,,function(e,a,t){e.exports=t.p+"static/media/audio-vault-enc-dec-application.drawio.f830d3cb.png"},function(e,a,t){e.exports=t(24)},,,,,,,,,function(e,a,t){},function(e,a,t){},function(e,a,t){"use strict";t.r(a);var n=t(1),r=t.n(n),l=t(10),i=t.n(l),o=(t(22),t(5)),c=t(3),s=t(4),m=t(6),u=t.n(m),h=t(11);var d=function(){return r.a.createElement("div",{style:{maxWidth:"900px",margin:"0 auto",textAlign:"center",padding:"1rem"}},r.a.createElement("h1",null,"Girish .  "),r.a.createElement("div",{style:{display:"flex",alignItems:"center",justifyContent:"center",marginBottom:"2rem",flexWrap:"wrap"}},r.a.createElement("div",{style:{flex:"1 1 300px",textAlign:"left",padding:"1rem"}},r.a.createElement("p",null,"Greetings\u2014I am Girish, currently in my final year of the Bachelor of Technology (Hons) in Computer Science & Engineering, specializing in Artificial Intelligence & Machine Learning at UPES. I anticipate graduating in June 2026."),r.a.createElement("p",null,"My present research focuses on advanced speech and audio technologies, including emotion recognition, deepfake detection in audio streams, and the development of novel audio language models."),r.a.createElement("p",null,"Previously, I served as a Research Associate at IIIT Delhi and have collaborated with organizations such as Reliance Jio, ARTVIEWINGS LLC, Suratec Co., Ltd., and Ulster University."),r.a.createElement("p",null,"I have contributed papers to premier conferences including Interspeech and ICASSP, with several additional manuscripts currently under review."),r.a.createElement("p",null,"Core competencies: Python, Java, C++, TensorFlow, PyTorch, audio signal processing, NLP, and generative AI.")),r.a.createElement("div",{style:{flex:"1 1 300px",textAlign:"center",padding:"1rem"}},r.a.createElement("img",{src:u.a,alt:"Girish",style:{maxWidth:"50%",height:"auto",borderRadius:"35%"}}))),r.a.createElement("h2",null,"Recent Updates"),r.a.createElement("ul",{style:{textAlign:"left",maxWidth:"600px",margin:"0 auto"}},r.a.createElement("li",null,"Awaiting acceptance notifications for EUSIPCO 2025 and Interspeech 2025."),r.a.createElement("li",null,"Submitted (or preparing submissions) to EMNLP 2025, ECAI 2025, and ASRU 2025."),r.a.createElement("li",null,"Co-founding the Non-Euclidean Speech Lab, focusing on geometric approaches to audio analysis."),r.a.createElement("li",null,"Launching Helix, a company building AI agents and their applications.")),r.a.createElement("div",{style:{marginTop:"2rem",textAlign:"center"}},r.a.createElement("h2",null,"Contact"),r.a.createElement("div",{style:{display:"flex",justifyContent:"center",gap:"1.5rem"}},r.a.createElement("a",{href:"https://linkedin.com/in/girish-b794092a1/",target:"_blank",rel:"noopener noreferrer","aria-label":"LinkedIn"},r.a.createElement(s.d,{style:{fontSize:"2.5rem",color:"#0e76a8"}})),r.a.createElement("a",{href:"https://github.com/gir-ish",target:"_blank",rel:"noopener noreferrer","aria-label":"GitHub"},r.a.createElement(s.c,{style:{fontSize:"2.5rem",color:"#333"}})),r.a.createElement("a",{href:"https://scholar.google.com/citations?user=4HIGa7AAAAAJ&hl=en",target:"_blank",rel:"noopener noreferrer","aria-label":"Google Scholar"},r.a.createElement(h.a,{style:{fontSize:"2.5rem",color:"#4285F4"}})),r.a.createElement("a",{href:"mailto:girish.research.pr@gmail.com",target:"_blank",rel:"noopener noreferrer","aria-label":"Email"},r.a.createElement(s.a,{style:{fontSize:"2.5rem",color:"red"}})))))};t(8);var E=function(){return r.a.createElement("div",{style:{textAlign:"left",maxWidth:"800px",margin:"0 auto",padding:"1rem"}},r.a.createElement("h1",{style:{textAlign:"center"}},"Publications"),r.a.createElement("h2",{style:{textDecoration:"underline"}},"Accepted"),r.a.createElement("ul",null,r.a.createElement("li",null,"SOURCE TRACING OF SYNTHETIC SPEECH SYSTEMS THROUGH PARALINGUISTIC PRE-TRAINED REPRESENTATIONS"," ",r.a.createElement("span",{style:{color:"#297aeb"}},"(Eusipco 2025)")," ",r.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: ",r.a.createElement("strong",null,"Girish*"),", Mohd Mujtaba Akhtar*, Orchid Chetia Phukan*, Drishti Singh, Swarup Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma"))),r.a.createElement("br",null),r.a.createElement("li",null,"ARE MAMBA-BASED AUDIO FOUNDATION MODELS THE BEST FIT FOR NON-VERBAL EMOTION RECOGNITION?"," ",r.a.createElement("span",{style:{color:"#297aeb"}},"(Eusipco 2025)")," ",r.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Mohd Mujtaba Akhtar*, Orchid Chetia Phukan*, ",r.a.createElement("strong",null,"Girish*"),", Swarup Ranjan Behera, Sanjib, Arun Balaji Buduru, Rajesh Sharma"))),r.a.createElement("br",null),r.a.createElement("li",null,"Investigating the Reasonable Effectiveness of Speaker Pre-Trained Models and their Synergistic Power for SingMOS Prediction"," ",r.a.createElement("span",{style:{color:"#297aeb"}},"(INTERSPEECH 2025)")," ",r.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Orchid Chetia Phukan*, ",r.a.createElement("strong",null,"Girish*"),", Mohd Mujtaba Akhtar*, Swarup Ranjan Behera, PhD Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma"))),r.a.createElement("br",null),r.a.createElement("li",null,"Towards Source Attribution of Singing Voice Deepfake with Multimodal Foundation Models"," ",r.a.createElement("span",{style:{color:"#297aeb"}},"(INTERSPEECH 2025)")," ",r.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Orchid Chetia Phukan*, ",r.a.createElement("strong",null,"Girish*"),", Mohd Mujtaba Akhtar*, Swarup Ranjan Behera, PhD Ranjan Behera, Priyabrata Mallick, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma"))),r.a.createElement("br",null),r.a.createElement("li",null,"PARROT: Synergizing Mamba and Attention-based SSL Pre-Trained Models via Parallel Branch Hadamard Optimal Transport for Speech Emotion Recognition"," ",r.a.createElement("span",{style:{color:"#297aeb"}},"(INTERSPEECH 2025)")," ",r.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Orchid Chetia Phukan*, Mohd Mujtaba Akhtar*, ",r.a.createElement("strong",null,"Girish*"),", Swarup Ranjan Behera, PhD, Sai Kiran Patibandla, Arun Balaji Buduru, Rajesh Sharma"))),r.a.createElement("br",null),r.a.createElement("li",null,"HYFuse: Aligning Heterogeneous Speech Pre-Trained Representations in Hyperbolic Space for Speech Emotion Recognition"," ",r.a.createElement("span",{style:{color:"#297aeb"}},"(INTERSPEECH 2025)")," ",r.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Orchid Chetia Phukan*, ",r.a.createElement("strong",null,"Girish*"),", Mohd Mujtaba Akhtar*, Swarup Ranjan Behera, PhD Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma"))),r.a.createElement("br",null),r.a.createElement("li",null,"SNIFR: Boosting Fine-Grained Child Harmful Content Detection Through Audio-Visual Alignment with Cascaded Cross-Transformer"," ",r.a.createElement("span",{style:{color:"#297aeb"}},"(INTERSPEECH 2025)")," ",r.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Orchid Chetia Phukan*, Mohd Mujtaba Akhtar*, ",r.a.createElement("strong",null,"Girish*"),", Swarup Ranjan Behera, PhD, Abu Osama Siddiqui, Sarthak Jain, Priyabrata Mallick, Sai Kiran Patibandla, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma"))),r.a.createElement("br",null),r.a.createElement("li",null,"Towards Machine Unlearning for Paralinguistic Speech Processing"," ",r.a.createElement("span",{style:{color:"#297aeb"}},"(INTERSPEECH 2025)")," ",r.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Orchid Chetia Phukan*, ",r.a.createElement("strong",null,"Girish*"),", Mohd Mujtaba Akhtar*, Shubham Singh, Swarup Ranjan Behera, PhD, Vandana Malayil/Rajan, Ph.D, Muskaan Singh, Arun Balaji Buduru, Rajesh Sharma"))),r.a.createElement("br",null),r.a.createElement("li",null,"Towards Fusion of Neural Audio Codec-based Representations with Spectral for Heart Murmur Classification via Bandit-based Cross-Attention Mechanism"," ",r.a.createElement("span",{style:{color:"#297aeb"}},"(INTERSPEECH 2025)")," ",r.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Orchid Chetia Phukan*, ",r.a.createElement("strong",null,"Girish*"),", Mohd Mujtaba Akhtar*, Swarup Ranjan Behera, PhD, Priyabrata Mallick, Santanu Roy, Arun Balaji Buduru, Rajesh Sharma"))),r.a.createElement("br",null),r.a.createElement("li",null,"Strong Alone, Stronger Together: Synergizing Modality-Binding Foundation Models with Optimal Transport for Non-Verbal Emotion Recognition"," ",r.a.createElement("span",{style:{color:"#297aeb"}},"(ICASSP 2025)")," ",r.a.createElement("a",{href:"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4HIGa7AAAAAJ&citation_for_view=4HIGa7AAAAAJ:9yKSN-GCB0IC",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Orchid Chetia Phukan, Mohd Mujtaba Akhtar*, ",r.a.createElement("strong",null,"Girish*"),", Swarup Ranjan Behera, Sishir Kalita, Arun Balaji Buduru, Rajesh Sharma, SR Mahadeva Prasanna"))),r.a.createElement("br",null),r.a.createElement("li",null,"NeuRO: An Application for Code-Switched Autism Detection in Children"," ",r.a.createElement("span",{style:{color:"#297aeb"}},"(Interspeech Show & Tell 2024)")," ",r.a.createElement("a",{href:"https://ui.adsabs.harvard.edu/abs/2024arXiv240603514M/abstract",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Mohd Mujtaba Akhtar*, ",r.a.createElement("strong",null,"Girish*"),", Orchid Chetia Phukan*, Muskaan Singh*")))),r.a.createElement("h2",{style:{textDecoration:"underline"}},"Preprints / Submitted"),r.a.createElement("ul",null,r.a.createElement("li",null,"ARE MULTIMODAL FOUNDATION MODELS ALL THAT IS NEEDED FOR EMOFAKE DETECTION?"," ",r.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Mohd Mujtaba Akhtar*, ",r.a.createElement("strong",null,"Girish*"),", Orchid Chetia Phukan*, Swarup Ranjan Behera, Jaya Sai Kiran Patibandla, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma"))),r.a.createElement("br",null),r.a.createElement("li",null,"SYNERGIZING NEURAL AUDIO CODEC AND SPECTRAL REPRESENTATIONS FOR DEPRESSION DETECTION"," ",r.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Mohd Mujtaba Akhtar*, ",r.a.createElement("strong",null,"Girish*"),", Orchid Chetia Phukan*, Swarup Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma"))),r.a.createElement("br",null),r.a.createElement("li",null,"Representation Loss Minimization with Randomized Selection Strategy for Efficient Environmental Fake Audio Detection"," ",r.a.createElement("a",{href:"#",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Orchid Chetia Phukan*, ",r.a.createElement("strong",null,"Girish*"),", Mohd Mujtaba Akhtar*, Swarup Ranjan Behera*, Nitin Choudhury, Arun Balaji Buduru, Rajesh Sharma, SR Mahadeva Prasanna"))),r.a.createElement("br",null),r.a.createElement("li",null,"Beyond Speech and More: Investigating the Emergent Ability of Speech Foundation Models for Classifying Physiological Time-Series Signals"," ",r.a.createElement("a",{href:"https://arxiv.org/abs/2410.12645",target:"_blank",rel:"noopener noreferrer",title:"View PDF"},r.a.createElement(s.b,{style:{color:"red",verticalAlign:"middle"}})),r.a.createElement("div",{style:{marginTop:"10px"}},r.a.createElement("em",null,"Authors: Orchid Chetia Phukan*, Swarup Ranjan Behera*, ",r.a.createElement("strong",null,"Girish*"),", Mohd Mujtaba Akhtar*, Arun Balaji Buduru, Rajesh Sharma")))))},p=t(12),g=t.n(p);var f=function(){return r.a.createElement("div",{style:{maxWidth:"1000px",margin:"0 auto",padding:"1rem",textAlign:"left"}},r.a.createElement("h1",null,"Projects"),r.a.createElement("ol",null,r.a.createElement("li",{style:{marginBottom:"2rem"}},r.a.createElement("div",{style:{display:"flex",alignItems:"center",flexWrap:"wrap"}},r.a.createElement("h2",{style:{margin:0}},"Helix: Versatile AI Assistant",r.a.createElement("a",{href:"https://github.com/voice-chat-agent/WhatsApp-bot",target:"_blank",rel:"noopener noreferrer",style:{marginLeft:"1rem"},title:"View on GitHub"},r.a.createElement(s.c,{style:{fontSize:"1.8rem",color:"#333",position:"relative",top:"8px"}}))),r.a.createElement("br",null)),r.a.createElement("br",null),r.a.createElement("ul",null,r.a.createElement("li",null,"AI-Powered Smart Responses: Uses OpenAI GPT, LangChain, and Pinecone for real-time, context-aware interactions, improving customer engagement and automation."),r.a.createElement("li",null,"Versatile \\& Scalable: Easily deploys across industries like healthcare, retail, and finance with minimal code changes, ensuring seamless adaptability."),r.a.createElement("li",null,"Omnichannel \\& Fast: Connects via WhatsApp (Twilio) and phone calls, with a FastAPI backend and async MongoDB for quick, efficient responses."),r.a.createElement("li",null,"Tools Used: LangChain, FastAPI, MongoDB, Twilio."))),r.a.createElement("li",{style:{marginBottom:"2rem"}},r.a.createElement("div",{style:{display:"flex",alignItems:"center",flexWrap:"wrap"}},r.a.createElement("h2",{style:{margin:0}},"TwinVerify: Secure Encryption with Two-Factor Audio and Text Authentication Framework",r.a.createElement("a",{href:"https://github.com/gir-ish/TwinVerify",target:"_blank",rel:"noopener noreferrer",style:{marginLeft:"1rem"},title:"View on GitHub"},r.a.createElement(s.c,{style:{fontSize:"1.8rem",color:"#333",position:"relative",top:"8px"}})))),r.a.createElement("br",null),r.a.createElement("ul",null,r.a.createElement("li",null,"Designed audio encryption and decryption mechanisms with dual-step authentication."),r.a.createElement("li",null,"Combined voice verification with text-based answer matching for secure access."),r.a.createElement("li",null,"Developed the application using Python with the Flask web framework.")),r.a.createElement("img",{src:g.a,alt:"TwinVerify Project",style:{maxWidth:"50%",height:"auto",marginTop:"1rem"}})),r.a.createElement("li",{style:{marginBottom:"2rem"}},r.a.createElement("div",{style:{display:"flex",alignItems:"center",flexWrap:"wrap"}},r.a.createElement("h2",{style:{margin:0}},"Multimodal Personality Prediction Using Contrastive Learning",r.a.createElement("a",{href:"https://github.com/gir-ish/Personality-Detection",target:"_blank",rel:"noopener noreferrer",style:{marginLeft:"1rem"},title:"View on GitHub"},r.a.createElement(s.c,{style:{fontSize:"1.8rem",color:"#333",position:"relative",top:"8px"}})))),r.a.createElement("br",null),r.a.createElement("ul",null,r.a.createElement("li",null,"Built a neural network with two processing paths that uses contrastive learning to predict personality traits (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) from audio and video data."),r.a.createElement("li",null,"Trained the model on both speech and visual cues, improving how it understands and learns personality traits from different sources."),r.a.createElement("li",null,"Optimized the system for better integration of multimodal data, ensuring accurate and reliable personality predictions from real-world audio and video inputs."),r.a.createElement("li",null,"Tools Used: TensorFlow, Hugging Face Transformers."))),r.a.createElement("li",{style:{marginBottom:"2rem"}},r.a.createElement("div",{style:{display:"flex",alignItems:"center",flexWrap:"wrap"}},r.a.createElement("h2",{style:{margin:0}},"Golf Phase Detection and Analysis Application.",r.a.createElement("a",{href:"https://github.com/gir-ish/Golf_Phase_Detection",target:"_blank",rel:"noopener noreferrer",style:{marginLeft:"1rem"},title:"View on GitHub"},r.a.createElement(s.c,{style:{fontSize:"1.8rem",color:"#333",position:"relative",top:"8px"}})))),r.a.createElement("br",null),r.a.createElement("ul",null,r.a.createElement("li",null,"Developed algorithms to detect and classify golf swing phases (setup, backswing, downswing, ball impact, and follow-through) with high accuracy."),r.a.createElement("li",null,"Designed a user-friendly interface for players and coaches, enabling easy review and real-time analysis across different video formats."),r.a.createElement("li",null,"Tools Used: OpenCV, MediaPipe, FFmpeg, Streamlit")))))};t(23);var b=function(){const[e,a]=Object(n.useState)(!1);return r.a.createElement("div",{className:e?"App dark":"App light"},r.a.createElement(o.a,null,r.a.createElement("header",{className:"header"},r.a.createElement("nav",null,r.a.createElement("ul",{className:"nav-links"},r.a.createElement("li",null,r.a.createElement(o.b,{to:"/about"},"About")),r.a.createElement("li",null,r.a.createElement(o.b,{to:"/publication"},"Publication")),r.a.createElement("li",null,r.a.createElement(o.b,{to:"/project"},"Project"))),r.a.createElement("button",{className:"theme-toggle",onClick:()=>a(!e)},e?r.a.createElement(s.f,{style:{color:"yellow",fontSize:"1.5rem"}}):r.a.createElement(s.e,{style:{color:"blue",fontSize:"1.5rem"}}))),r.a.createElement("hr",{className:"divider"})),r.a.createElement("main",{className:"container"},r.a.createElement(c.c,null,r.a.createElement(c.a,{path:"/about",element:r.a.createElement(d,null)}),r.a.createElement(c.a,{path:"/publication",element:r.a.createElement(E,null)}),r.a.createElement(c.a,{path:"/project",element:r.a.createElement(f,null)})))))};var y=e=>{e&&e instanceof Function&&t.e(3).then(t.bind(null,25)).then(a=>{let{getCLS:t,getFID:n,getFCP:r,getLCP:l,getTTFB:i}=a;t(e),n(e),r(e),l(e),i(e)})};i.a.createRoot(document.getElementById("root")).render(r.a.createElement(r.a.StrictMode,null,r.a.createElement(b,null))),y()}],[[13,1,2]]]);
//# sourceMappingURL=main.c4b6dcf5.chunk.js.map